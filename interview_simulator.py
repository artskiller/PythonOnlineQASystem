#!/usr/bin/env python3
"""
é¢è¯•æ¨¡æ‹Ÿå™¨ - 2å°æ—¶é™æ—¶ç»ƒä¹ 

ç”¨æ³•ï¼š
  python interview_simulator.py --duration 120 --focus tax    # ä¾§é‡è´¢ç¨Ž
  python interview_simulator.py --duration 120 --difficulty medium
  python interview_simulator.py --random 10                   # éšæœº10é¢˜
"""

from __future__ import annotations

import argparse
import json
import random
import subprocess
import sys
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List

# é¢˜ç›®åˆ†ç±»é…ç½®
QUESTION_SETS = {
    # è´¢ç¨Žä¸šåŠ¡ï¼ˆé‡ç‚¹ï¼‰
    "tax": {
        "sets": ["E", "J", "F", "Q"],
        "description": "è´¢ç¨Žä¸šåŠ¡ï¼ˆä¸ªç¨Ž/å¢žå€¼ç¨Ž/å‘ç¥¨/åˆè§„ï¼‰",
        "weight": 3,  # æƒé‡
    },
    # AIæŠ€èƒ½ï¼ˆæ–°å¢žï¼‰
    "ai": {
        "sets": ["ML1", "NLP1", "OCR1"],
        "description": "AIæŠ€èƒ½ï¼ˆæœºå™¨å­¦ä¹ /NLP/OCRï¼‰",
        "weight": 3,
    },
    "ml": {
        "sets": ["ML1"],
        "description": "æœºå™¨å­¦ä¹ åŸºç¡€",
        "weight": 1,
    },
    "nlp": {
        "sets": ["NLP1"],
        "description": "è‡ªç„¶è¯­è¨€å¤„ç†",
        "weight": 1,
    },
    "ocr": {
        "sets": ["OCR1"],
        "description": "OCRå›¾åƒè¯†åˆ«",
        "weight": 1,
    },
    # æ•°æ®å¤„ç†
    "data": {
        "sets": ["B", "G"],
        "description": "æ•°æ®å¤„ç†ï¼ˆpandas/numpyï¼‰",
        "weight": 2,
    },
    # å¹¶å‘ç¼–ç¨‹
    "concurrency": {
        "sets": ["D", "H", "T"],
        "description": "å¹¶å‘ç¼–ç¨‹ï¼ˆasyncio/threadingï¼‰",
        "weight": 2,
    },
    # ç³»ç»Ÿè®¾è®¡
    "system": {
        "sets": ["R", "S", "U", "V", "W", "X", "Y"],
        "description": "ç³»ç»Ÿè®¾è®¡ï¼ˆAPI/æ—¥å¿—/è¿½è¸ªï¼‰",
        "weight": 1,
    },
    # åŸºç¡€
    "basics": {
        "sets": ["A", "K", "L", "M", "N", "P"],
        "description": "PythonåŸºç¡€ä¸Žå·¥ç¨‹å®žè·µ",
        "weight": 1,
    },
    # ç®—æ³•
    "algorithm": {
        "sets": ["C", "I", "O"],
        "description": "ç®—æ³•ä¸Žæ•°æ®ç»“æž„",
        "weight": 1,
    },
    # é¡¹ç›®
    "project": {
        "sets": ["Z", "AA", "AB"],
        "description": "ç«¯åˆ°ç«¯é¡¹ç›®",
        "weight": 1,
    },
}

# éš¾åº¦é…ç½®
DIFFICULTY_SETS = {
    "easy": ["A", "K", "L", "M", "X", "F"],
    "medium": ["B", "C", "D", "N", "P", "R", "S", "E"],
    "hard": ["G", "H", "I", "J", "O", "Q", "T", "U", "V", "W", "Y"],
    "expert": ["Z", "AA", "AB"],
}


def select_questions(
    focus: str | None = None,
    difficulty: str | None = None,
    count: int | None = None,
    random_seed: int | None = None,
) -> List[str]:
    """é€‰æ‹©é¢˜ç›®"""
    if random_seed is not None:
        random.seed(random_seed)

    selected = []

    if focus:
        # æŒ‰ä¸»é¢˜é€‰æ‹©
        if focus in QUESTION_SETS:
            sets = QUESTION_SETS[focus]["sets"]
            selected = sets if count is None else random.sample(sets, min(count, len(sets)))
        else:
            print(f"âš ï¸  æœªçŸ¥ä¸»é¢˜: {focus}")
            print(f"å¯ç”¨ä¸»é¢˜: {', '.join(QUESTION_SETS.keys())}")
            sys.exit(1)
    elif difficulty:
        # æŒ‰éš¾åº¦é€‰æ‹©
        if difficulty in DIFFICULTY_SETS:
            sets = DIFFICULTY_SETS[difficulty]
            selected = sets if count is None else random.sample(sets, min(count, len(sets)))
        else:
            print(f"âš ï¸  æœªçŸ¥éš¾åº¦: {difficulty}")
            print(f"å¯ç”¨éš¾åº¦: {', '.join(DIFFICULTY_SETS.keys())}")
            sys.exit(1)
    elif count:
        # éšæœºé€‰æ‹©
        all_sets = list(set(s for cat in QUESTION_SETS.values() for s in cat["sets"]))
        selected = random.sample(all_sets, min(count, len(all_sets)))
    else:
        # é»˜è®¤ï¼šè´¢ç¨Žä¸ºä¸»çš„æ··åˆ
        selected = []
        # è´¢ç¨Žé¢˜ç›®ï¼ˆ50%ï¼‰
        tax_sets = QUESTION_SETS["tax"]["sets"]
        selected.extend(random.sample(tax_sets, min(2, len(tax_sets))))
        # æ•°æ®å¤„ç†ï¼ˆ25%ï¼‰
        data_sets = QUESTION_SETS["data"]["sets"]
        selected.extend(random.sample(data_sets, 1))
        # å…¶ä»–ï¼ˆ25%ï¼‰
        other_sets = QUESTION_SETS["concurrency"]["sets"] + QUESTION_SETS["basics"]["sets"]
        selected.extend(random.sample(other_sets, 2))

    return sorted(selected)


def run_interview(
    questions: List[str],
    duration_minutes: int,
    output_dir: Path,
) -> Dict:
    """è¿è¡Œé¢è¯•æ¨¡æ‹Ÿ"""
    print("=" * 70)
    print("ðŸŽ¯ é¢è¯•æ¨¡æ‹Ÿå™¨")
    print("=" * 70)
    print()
    print(f"ðŸ“‹ é¢˜ç›®æ•°é‡: {len(questions)}")
    print(f"â±ï¸  é™æ—¶: {duration_minutes} åˆ†é’Ÿ")
    print(f"ðŸ“ é¢˜ç›®åˆ—è¡¨: {', '.join(questions)}")
    print()
    print("=" * 70)
    print()

    # åˆ›å»ºå·¥ä½œç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    work_dir = output_dir / f"interview_{timestamp}"
    work_dir.mkdir(parents=True, exist_ok=True)

    # å¤åˆ¶é¢˜ç›®åˆ°å·¥ä½œç›®å½•
    print("ðŸ“ å‡†å¤‡é¢˜ç›®æ–‡ä»¶...")
    for q in questions:
        src = Path(f"interview_exercises/set_{q}_blank.py")
        if src.exists():
            dst = work_dir / f"set_{q}_blank.py"
            dst.write_text(src.read_text())
            print(f"  âœ“ {dst.name}")

    print()
    print("=" * 70)
    print("â° é¢è¯•å¼€å§‹ï¼")
    print("=" * 70)
    print()
    print(f"ðŸ“‚ å·¥ä½œç›®å½•: {work_dir}")
    print()
    print("ðŸ’¡ æç¤º:")
    print("  1. åœ¨å·¥ä½œç›®å½•ä¸­ç¼–è¾‘é¢˜ç›®æ–‡ä»¶")
    print("  2. è¿è¡Œ python set_X_blank.py æµ‹è¯•")
    print("  3. æ—¶é—´åˆ°åŽä¼šè‡ªåŠ¨è¯„åˆ†")
    print()

    end_time = datetime.now() + timedelta(minutes=duration_minutes)
    print(f"â±ï¸  ç»“æŸæ—¶é—´: {end_time.strftime('%H:%M:%S')}")
    print()
    print("æŒ‰ Enter å¼€å§‹è®¡æ—¶...")
    input()

    start_time = time.time()
    print()
    print("â° è®¡æ—¶å¼€å§‹ï¼")
    print()

    # ç­‰å¾…æ—¶é—´ç»“æŸæˆ–ç”¨æˆ·æå‰ç»“æŸ
    try:
        print("ðŸ’¡ å®ŒæˆåŽæŒ‰ Ctrl+C æå‰ç»“æŸï¼Œæˆ–ç­‰å¾…æ—¶é—´åˆ°...")
        time.sleep(duration_minutes * 60)
        print("\nâ° æ—¶é—´åˆ°ï¼")
    except KeyboardInterrupt:
        print("\n\nâ¸ï¸  æå‰ç»“æŸ")

    elapsed = time.time() - start_time
    print()
    print("=" * 70)
    print("ðŸ“Š å¼€å§‹è¯„åˆ†...")
    print("=" * 70)
    print()

    # è¯„åˆ†
    results = {}
    passed = 0
    failed = 0

    for q in questions:
        test_file = work_dir / f"set_{q}_blank.py"
        if not test_file.exists():
            results[q] = {"status": "missing", "output": "æ–‡ä»¶ä¸å­˜åœ¨"}
            failed += 1
            continue

        try:
            result = subprocess.run(
                [sys.executable, str(test_file)],
                capture_output=True,
                timeout=10,
                cwd=work_dir,
            )
            if result.returncode == 0:
                results[q] = {"status": "passed", "output": result.stdout.decode()}
                passed += 1
                print(f"âœ… Set {q}: é€šè¿‡")
            else:
                results[q] = {
                    "status": "failed",
                    "output": result.stdout.decode() + result.stderr.decode(),
                }
                failed += 1
                print(f"âŒ Set {q}: å¤±è´¥")
        except subprocess.TimeoutExpired:
            results[q] = {"status": "timeout", "output": "è¶…æ—¶"}
            failed += 1
            print(f"â±ï¸  Set {q}: è¶…æ—¶")
        except Exception as e:
            results[q] = {"status": "error", "output": str(e)}
            failed += 1
            print(f"âŒ Set {q}: é”™è¯¯ - {e}")

    # ç”ŸæˆæŠ¥å‘Š
    report = {
        "timestamp": timestamp,
        "duration_minutes": duration_minutes,
        "elapsed_seconds": int(elapsed),
        "questions": questions,
        "total": len(questions),
        "passed": passed,
        "failed": failed,
        "score": round(passed / len(questions) * 100, 1) if questions else 0,
        "results": results,
    }

    report_file = work_dir / "report.json"
    report_file.write_text(json.dumps(report, indent=2, ensure_ascii=False))

    print()
    print("=" * 70)
    print("ðŸ“Š é¢è¯•ç»“æžœ")
    print("=" * 70)
    print()
    print(f"â±ï¸  ç”¨æ—¶: {int(elapsed // 60)} åˆ† {int(elapsed % 60)} ç§’")
    print(f"âœ… é€šè¿‡: {passed}/{len(questions)}")
    print(f"âŒ å¤±è´¥: {failed}/{len(questions)}")
    print(f"ðŸ“ˆ å¾—åˆ†: {report['score']}%")
    print()
    print(f"ðŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_file}")
    print()

    return report


def main(argv: List[str] | None = None) -> int:
    parser = argparse.ArgumentParser(description="é¢è¯•æ¨¡æ‹Ÿå™¨")
    parser.add_argument("--duration", type=int, default=120, help="æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰ï¼Œé»˜è®¤120")
    parser.add_argument("--focus", choices=list(QUESTION_SETS.keys()), help="ä¸»é¢˜ä¾§é‡")
    parser.add_argument("--difficulty", choices=list(DIFFICULTY_SETS.keys()), help="éš¾åº¦")
    parser.add_argument("--random", type=int, metavar="N", help="éšæœºé€‰æ‹©Né¢˜")
    parser.add_argument("--seed", type=int, help="éšæœºç§å­")
    parser.add_argument("--output", type=Path, default=Path("interview_results"), help="è¾“å‡ºç›®å½•")

    args = parser.parse_args(argv)

    # é€‰æ‹©é¢˜ç›®
    questions = select_questions(
        focus=args.focus,
        difficulty=args.difficulty,
        count=args.random,
        random_seed=args.seed,
    )

    if not questions:
        print("âŒ æ²¡æœ‰é€‰æ‹©ä»»ä½•é¢˜ç›®")
        return 1

    # è¿è¡Œé¢è¯•
    report = run_interview(questions, args.duration, args.output)

    # è¿”å›žç ï¼šé€šè¿‡çŽ‡ >= 60% ä¸ºæˆåŠŸ
    return 0 if report["score"] >= 60 else 1


if __name__ == "__main__":
    sys.exit(main())

